#!/usr/bin/env bds
#vim: syntax=java


help == atac pipeline settings

type 		:= "atac-seq" 	help Type of the pipeline. atac-seq or dnase-seq (default: atac-seq).
dnase_seq	:= false  	help DNase-Seq (no tn5 shifting).
trimmed_fastq 	:= false	help Skip fastq-trimming stage.
align	 	:= false	help Align only (no MACS2 peak calling or IDR or ataqc analysis).
subsample_xcor	:= "25M"	help # reads to subsample for cross corr. analysis (default: 25M).
subsample 	:= "0" 		help # reads to subsample exp. replicates. Subsampled tagalign will be used for steps downstream (default: 0; no subsampling).
true_rep 	:= false 	help No pseudo-replicates.
no_idr 		:= false 	help No IDR analysis on called peaks. This will change p-value threshold (0.1->0.01) in MACS2 peak calling.
no_ataqc 	:= false 	help No ATAQC
no_xcor 	:= false 	help No Cross-correlation analysis.
csem	 	:= false	help Use CSEM for alignment.
smooth_win 	:= "150" 	help Smoothing window size for MACS2 peak calling (default: 150).
idr_thresh 	:= "0.1"	help IDR threshold : -log_10(score) (default: 0.1).
old_trimmer 	:= false 	help Use legacy trim adapters (trim_galore and trimAdapter.py).
ENCODE3		:= false	help Force to use parameter set (-smooth_win 73 -idr_thresh 0.05 -multimapping 4) for ENCODE3.
ENCODE		:= false	help Force to use parameter set (-smooth_win 73 -idr_thresh 0.05 -multimapping 4) for ENCODE.



help() // show help contexts

include "modules/pipeline_template.bds"
include "modules/input.bds"
include "modules/input_adapter.bds"

include "modules/align_bowtie2.bds"
include "modules/align_trim_adapter.bds"
include "modules/align_etc.bds"

include "modules/postalign_bam.bds"
include "modules/postalign_bed.bds"

include "modules/callpeak_macs2.bds"
include "modules/callpeak_naive_overlap.bds"
include "modules/callpeak_filter.bds"
include "modules/callpeak_idr.bds"
include "modules/callpeak_blacklist_filter.bds"
include "modules/callpeak_bigbed.bds"

include "modules/ataqc.bds"
include "modules/ENCODE_accession.bds"

// Important output file names are stored in global variables (usually a string map string{} with a key with replicate id, pair id)
// e.g. filt_bam{"1"} = filtered bam for replicate 1, peak_pr1{"2"} = peak file for pseudo replicate 1 of replicate 2

string{} fastq, align_log, flagstat_qc, bam, filt_bam, dup_qc, flagstat_nodup_qc, pbc_qc, xcor_qc, xcor_plot
string{} final_tag, final_tag_pr1, final_tag_pr2

string{} peak, peak_001, peak_pr1, peak_pr2
string peak_pooled, peak_pooled_001, peak_ppr1, peak_ppr2, peak_overlap

string{} gpeak, gpeak_001, gpeak_pr1, gpeak_pr2
string gpeak_pooled, gpeak_pooled_001, gpeak_ppr1, gpeak_ppr2, gpeak_overlap

string{} pval_bigwig_001, fc_bigwig_001

string{} idr_tr, idr_pr, idr_tr_png, idr_pr_png, idr_tr_log, idr_pr_log
string idr_ppr, idr_opt, idr_consv, idr_ppr_png, idr_ppr_log

string idr_qc

string{} ataqc_qc

main()


void main() { // atac pipeline starts here

	init_atac()

	chk_param() // check if parameters are valid

	chk_adapters()

	chk_input( true_rep, false )

	print("DO ALIGN")
	do_align()

	#call_peaks()

	#read_input_peak() // if inputs are peaks, read them

	#do_idr()

	#ataqc()

	// blacklist-filter peaks and also make ENCODE accession metadata for them
	filter_peak_and_convert_to_bigbed() 

	report()
}

void init_atac() {

	read_conf_atac()

	init_etc_atac()

	print_atac()

	init_filetable()
}

void read_conf_atac() {

	type		= get_conf_val( type,			["type"] )
	trimmed_fastq 	= get_conf_val_bool( trimmed_fastq,	["trimmed_fastq"] )
	align		= get_conf_val_bool( align,		["align"] )
	true_rep	= get_conf_val_bool( true_rep, 		["true_rep"] )
	no_idr 		= get_conf_val_bool( no_idr, 		["no_idr"] )
	no_ataqc 	= get_conf_val_bool( no_ataqc, 		["no_ataqc"] )
	no_xcor 	= get_conf_val_bool( no_xcor, 		["no_xcor"] )
	csem 		= get_conf_val_bool( csem, 		["csem"] )
	smooth_win	= get_conf_val( smooth_win,		["smooth_win"] )
	dnase_seq 	= get_conf_val_bool( dnase_seq, 	["dnase_seq"] )
	idr_thresh 	= get_conf_val( idr_thresh, 		["idr_thresh"] )
	subsample_xcor 	= get_conf_val( subsample_xcor,		["subsample_xcor"] )
	subsample	= get_conf_val( subsample, 		["subsample"] )
	old_trimmer 	= get_conf_val_bool( old_trimmer,	["old_trimmer"] )
	ENCODE3	 	= get_conf_val_bool( ENCODE3,		["ENCODE3"] )
	ENCODE	 	= get_conf_val_bool( ENCODE,		["ENCODE","ENCODE1"] )
}

void init_etc_atac() {

	default_is_pe 	= true
	fraglen0 	= true // set fragment length explicitly as zero for cross corr. analysis
	if ( rm_chr_from_tag == "" ) rm_chr_from_tag = "chrM"; // remove lines with chrM in _bam_to_tag
}

void print_atac() {

	print( "\n\n== atac pipeline settings\n")
	print( "Type of pipeline\t\t\t: $type\n")
	print( "Fastqs are trimmed?\t\t\t: $trimmed_fastq\n")
	print( "Align only\t\t\t\t: " + align + "\n")
	print( "# reads to subsample replicates (0 if no subsampling)\t: "+parse_number( subsample )+"\n")
	print( "# reads to subsample for cross-corr. analysis \t: " +parse_number( subsample_xcor)+"\n")
	print( "No pseudo replicates\t\t\t: $true_rep\n")
	print( "No IDR analysis on peaks\t\t: $no_idr\n")
	print( "No ATAQC (advanced QC report)\t\t: $no_ataqc\n")
	print( "No Cross-corr. analysis\t\t\t: $no_xcor\n")
	print( "Use CSEM for alignment\t\t\t: $csem\n")
	print( "Smoothing window for MACS2\t\t: $smooth_win\n")
	print( "DNase Seq\t\t\t\t: $dnase_seq\n")
	print( "IDR threshold\t\t\t\t: $idr_thresh\n" )
	print( "Use old trim adapters\t\t\t: $old_trimmer\n" )
	print( "Force to use ENCODE3 parameter set\t: $ENCODE3\n" )
	print( "Force to use ENCODE parameter set\t: $ENCODE\n" )

	if ( dnase_seq ) type = "dnase-seq"	
}


void init_filetable() { // init file table labels in HTML report

	// add label to graphviz
	// : Items in filetable will be sorted in the ascending order of rank
 	// : Items added later will have higher rank

	// Level 1
	add_label_to_table("Alignment")
	add_label_to_table("Signal tracks")
	add_label_to_table("Peaks")
	add_label_to_table("QC and logs")

	// Level 2
	for (int i=1; i<=100; i++) \
		add_label_to_table("Replicate $i")
	
	add_label_to_table("True replicates")
	add_label_to_table("Pooled replicate")
	add_label_to_table("Pseudo-replicates")
	add_label_to_table("Pooled pseudo-replicate")
	add_label_to_table("Pooled pseudo-replicates")
	add_label_to_table("Optimal set")
	add_label_to_table("Conservative set")
	add_label_to_table("Naive overlap")
	add_label_to_table("MACS2")
	add_label_to_table("IDR")

	// Level 2 or 3
	add_label_to_table("Pseudo-replicate 1")
	add_label_to_table("Pseudo-replicate 2")
	add_label_to_table("Pooled pseudo-replicate 1")
	add_label_to_table("Pooled pseudo-replicate 2")
	for (int i=1; i<=20; i++) \
	    for (int j=i+1; j<=20; j++) \
	        add_label_to_table("Rep. $i vs Rep. $j")

	// Higher levels
	add_label_to_table("IDR QC")
	add_label_to_table("Fastq")
	add_label_to_table("Fastq 1")
	add_label_to_table("Fastq 2")
	add_label_to_table("Trimmed fastq")
	add_label_to_table("Trimmed fastq 1")
	add_label_to_table("Trimmed fastq 2")
	add_label_to_table("Bowtie2 map. log")
	add_label_to_table("Bam")
	add_label_to_table("Filtered bam")
	add_label_to_table("Sorted bam")
	add_label_to_table("Dedup. log")
	add_label_to_table("Bowtie2 map. flagstat log")
	add_label_to_table("PBC log")
	add_label_to_table("Bedpe")
	add_label_to_table("Subsampled bedpe")
	add_label_to_table("Tag-align")
	add_label_to_table("Subsampled tag-align")
	add_label_to_table("Cross-corr. log")
	add_label_to_table("Cross-corr. plot")
	add_label_to_table("P-value")
	add_label_to_table("Fold enrichment")
	add_label_to_table("Narrow peak")
	add_label_to_table("Gapped peak")
	add_label_to_table("Filtered narrow peak")
	add_label_to_table("Filtered gapped peak")
	add_label_to_table("IDR peak")
	add_label_to_table("Peak")
	add_label_to_table("Filtered peak")
	add_label_to_table("Filtered gapped peak")
	add_label_to_table("ATAQC")
	add_label_to_table("IDR plot")
	add_label_to_table("Unthresholded IDR peak")

	// add label to graphviz (short name, long name)

	for (int i=1; i<=50; i++) {
		add_label_to_graph("rep$i", "Replicate $i")
		add_label_to_graph("rep$i-pr1", "Pseudo-replicate 1 for rep. $i")
		add_label_to_graph("rep$i-pr2", "Pseudo-replicate 2 for rep. $i")
		add_label_to_graph("rep$i-pr", "Pseudo replicates for rep. $i")
		for (int j=1; j<=20; j++) {
			add_label_to_graph("rep$i-rep$j", "Rep. $i vs. Rep. $j")
		}
	}
	add_label_to_graph("pooled_rep", "Pooled replicate")
	add_label_to_graph("ppr", "Pooled pseudo-replicates")
	add_label_to_graph("ppr1", "Pooled pseudo-replicate 1")
	add_label_to_graph("ppr2", "Pooled pseudo-replicate 2")
}

void chk_param() {

	print( "\n== checking atac parameters ...\n" );

	if ( has_input_fastq() ) chk_align_bwt2()
	if ( !align ) 		chk_callpeak_macs2()
	if ( !no_idr ) 		chk_idr()
	if ( !no_ataqc ) {
		no_ataqc = !chk_ataqc()
	}

	if ( has_pe_input_tag() && subsample > 0 ) {
		print("Warning: Cannot subsample paired end tagaligns. Disabling subsampling...\n")
		subsample = 0
	}

	if ( !has_input_fastq() && !no_ataqc ) {
		print("Warning: ATAQC is available for fastq inputs only. Disabling ATAQC...\n")
		no_ataqc = true
	}

	if ( has_pe_input_fastq() && csem ) {
		error("CSEM (-csem) is not available for paired end fastqs!\n")
	}

	//if ( get_num_rep() > 2 && !no_idr ) {
	//	print("Warning: IDR is available for one replicate or two replicates only. Disabling IDR...\n")
	//	no_idr 	= true
	//}

	if ( ENCODE ) {
		print("Info: ENCODE flag is on (-smooth_win 73 -idr_thresh 0.05 -multimapping 4).\n")
		smooth_win = 73
		idr_thresh = 0.05
		multimapping = 4
	}
	if ( ENCODE3 ) {
		print("Info: ENCODE3 flag is on (-smooth_win 73 -idr_thresh 0.05 -multimapping 4).\n")
		smooth_win = 73
		idr_thresh = 0.05
		multimapping = 4
	}

	//ENCODE_assay_category = "DNA accessibility"
	if ( dnase_seq ) {
		ENCODE_assay_title = "DNase-seq"
	}
	else {
		ENCODE_assay_title = "ATAC-seq"
	}
}

void chk_adapters() {

	print( "\n== checking adapters to be trimmed ...\n" );

	// check adapters
	for ( int rep=1; rep <= get_num_rep(); rep++) {

		string prefix
		if ( is_input_fastq( rep ) ) {

			if ( !trimmed_fastq && !old_trimmer ) { // check adapters
				adapters := get_adapters( rep )
				
				prefix += "Replicate $rep adapters : "

				if ( adapters.size()==0 ) {
					prefix += "automatically detected"
				}
				else {
					for ( int i=0; i<adapters.size(); i++) {
						prefix = prefix + adapters[i] + ", "
						if ( adapters[i] == "" ) {
							print("$prefix :\n")
							error("Adapter sequence (-adapter, -adapter[REP_ID] for SE or "\
								+"-adapter[REP_ID]_[PAIR_ID] for PE) must be defined for adapter trimmer!\n")
						}
					}
				}
				
			}

			//if ( !is_se( rep ) && fastqs.size() < 2 ) \
			//	error("A pair of fastqs are needed for replicate $rep (if it's single-ended add '-se')\n")
		}
		print("$prefix\n")
	}
}

void do_align() {

	if ( is_input_peak() ) return

	// filesize of input ( map with key $rep )
	int{} filesize

	for ( int rep=1; rep <= get_num_rep(); rep++) {

		// check file size to distribute nth to each nth_app
		// determine # threads for each app related to alignment

		// get file size in bytes
		if ( is_input_fastq( rep ) ) {

			fastqs := get_fastqs( rep )
			filesize{rep} = (fastqs[0]).size()
			if ( fastqs.size() > 1) filesize{rep} += (fastqs[1]).size()*3 // multiply 3 to allocate more cpus for align
		}
		else if ( is_input_bam( rep ) ) 	filesize{rep} = (get_bam( 0, rep )).size()
		else if ( is_input_filt_bam( rep ) ) 	filesize{rep} = (get_filt_bam( 0, rep )).size()
		else if ( is_input_tag( rep ) ) 	filesize{rep} = (get_tag( 0, rep )).size()*10
	}

	//// distribute # threads for each replicate
	nth_rep := distribute_nonzero( nth, filesize ) // distribute # threads according to input filesize

	print("\n== Aligning...")
	for (int rep=1; rep<=get_num_rep(); rep++) {

		if ( no_par ) do_align( rep, nth_rep{rep} )
		else 	  par do_align( rep, nth_rep{rep} )
	}

	wait

	print( "\n== Done do_align()\n" )
}

void do_align( int rep, int nth_rep ) {

	if ( is_se( rep ) ) 	align_SE( rep, nth_rep )
	else 			align_PE( rep, nth_rep )
}

void align_SE( int rep, int nth_rep ) {

	group 	:= get_group_name( rep )
	long 	:= get_long_group_name( rep )

	aln_o_dir := mkdir( "$out_dir/align/$group" ) // create align output directory
	qc_o_dir  := mkdir( "$out_dir/qc/$group" ) // create qc output dir.

	string bam_, read_length_log, flagstat_qc_
	string[] fastqs

	if ( is_input_fastq( rep ) ) {

		fastqs = get_fastqs( rep )

		string[] trimmed_fastqs
		for ( int i=0; i<fastqs.size(); i++) {
			id := i+1
			suffix := fastqs.size()==1 ? "" : ":$id"

			add_file_to_report( fastqs[i], "fastq$suffix", group, "Alignment/$long/Fastq$suffix" )

			if ( trimmed_fastq ) {
				trimmed_fastqs.add( fastqs[i] )
			}
			else {
				string p1
				if ( old_trimmer ) {
					p1 = trim_adapters_old( fastqs[i], aln_o_dir, group, suffix )
				}
				else {
					adapters := get_adapters( rep )

					if ( adapters.size()==0 ) {
						string adapter_log, tid
						(adapter_log, tid) = detect_adapter( fastqs[i], qc_o_dir, group )
						wait tid

						adapter := parse_adapter_log( adapter_log )

						print("\nDetected adapter for $group (SE) : $adapter\n")
						adapters.add( adapter )
					}

					p1 = trim_adapters( fastqs[i], adapters[0], aln_o_dir, group, suffix )
				}
				trimmed_fastqs.add( p1 )
				add_file_to_report( p1, "trimmed\\nfastq$suffix" , group, "Alignment/$long/Trimmed fastq$suffix" )
			}

			if ( i==0 ) read_length_log = get_read_length_log( trimmed_fastqs[0], qc_o_dir, group )
		}
		wait

		string p1
		if ( trimmed_fastqs.size() > 1 ) { // if multiple fastqs are given, pool trimmed fastqs
			p1 = pool_fastq( trimmed_fastqs, aln_o_dir, group )
			add_file_to_report( p1, "pooled\\nfastq" , group, "Alignment/$long/Pooled fastq" )
			wait
		}
		else {
			p1 = trimmed_fastqs[0]
		}
		fastq{rep} = p1

		string align_log_ 

 		if ( csem ) {
			( bam_, align_log_ ) = bowtie2_csem( p1, aln_o_dir, qc_o_dir, group, nth_rep, !trimmed_fastq )
		}
		else {
			( bam_, align_log_ ) = bowtie2( p1, aln_o_dir, qc_o_dir, group, nth_rep, !trimmed_fastq )
		}
		wait

		flagstat_qc_ = samtools_flagstat_bam( bam_, qc_o_dir, group )

		bam{rep} = bam_
		align_log{rep} = align_log_
		flagstat_qc{rep} = flagstat_qc_

		add_file_to_report( bam_, "bam", group, "Alignment/$long/Bam" )		
		add_file_to_table( align_log_, "QC and logs/$long/Bowtie2 map. log")
		add_file_to_table( flagstat_qc_, "QC and logs/$long/Bowtie2 map. flagstat log")
	}

	string filt_bam_, dup_qc_, pbc_qc_

	if ( is_input_fastq( rep ) || is_input_bam( rep ) ) {

		if ( is_input_bam( rep ) ) {
			bam_ = get_bam( 0, rep )
			bam{rep} = bam_
		}

		if ( no_dup_removal ) {
			string tmp
			( filt_bam_, tmp ) = dedup_bam( bam_, aln_o_dir, qc_o_dir, group, nth_rep )
		}
		else {
			( filt_bam_, dup_qc_, flagstat_nodup_qc{rep}, pbc_qc_ ) \
							= dedup_bam( bam_, aln_o_dir, qc_o_dir, group, nth_rep )
			dup_qc{rep} = dup_qc_
			pbc_qc{rep} = pbc_qc_
			add_file_to_table( dup_qc_, "QC and logs/$long/Dedup. log")
		}
		filt_bam{rep} = filt_bam_

		add_file_to_report( filt_bam_, "filt. bam", group, "Alignment/$long/Filtered & deduped bam" )

		wait

		if ( fastqs.size() > 0 ) \
			add_ENCODE_metadata_to_summary_json( "bam", "", "alignments", \
				"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", filt_bam_, fastqs )
		if ( flagstat_qc_ ) { 
			add_ENCODE_quality_metrics_to_summary_json( "samtools_flagstats_quality_metric", \
				"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", [filt_bam_], [flagstat_qc_] )
		}
	}

	string tag

	if ( is_input_fastq( rep ) || is_input_bam( rep ) || is_input_filt_bam( rep ) ) {

		if ( is_input_filt_bam( rep ) ) {
			filt_bam_ = get_filt_bam( 0, rep )
			filt_bam{rep} = filt_bam_
		}

		tag = bam_to_tag( filt_bam_, aln_o_dir, group )

		wait
	}

	string final_tag_, final_tag_pr1_, final_tag_pr2_

	if ( is_input_fastq( rep ) || is_input_bam( rep ) || is_input_filt_bam( rep ) || is_input_tag( rep ) ) {

		if ( is_input_tag( rep ) ) tag = get_tag( 0, rep )

		string subsampled_tag

		if ( parse_number( subsample ) != 0 ) {
			subsampled_tag = subsample_tag( tag, parse_number( subsample ), aln_o_dir, group )
			wait
		}
		else {
			subsampled_tag = tag
		}

		if ( is_dnase_seq() ) {
			final_tag_ = subsampled_tag
		}
		else {
			final_tag_ = tn5_shift_tag( subsampled_tag, aln_o_dir, group )
		}

		final_tag{rep} = final_tag_

		add_file_to_report( final_tag_, "tag-align", group, "Alignment/$long/Tag-align" )

		wait

		if ( !true_rep ) {

			aln_pr1_o_dir := mkdir( "$out_dir/align/pseudo_reps/$group/pr1" )
			aln_pr2_o_dir := mkdir( "$out_dir/align/pseudo_reps/$group/pr2" )

			( final_tag_pr1_, final_tag_pr2_ ) = spr( final_tag_, aln_pr1_o_dir, aln_pr2_o_dir, group )
			final_tag_pr1{rep} = final_tag_pr1_
			final_tag_pr2{rep} = final_tag_pr2_

			add_file_to_report( final_tag_pr1_, "tag-align", "$group-pr1", "Alignment/Pseudo-replicates/$long/Pseudo-replicate 1/Tag-align" )
			add_file_to_report( final_tag_pr2_, "tag-align", "$group-pr2", "Alignment/Pseudo-replicates/$long/Pseudo-replicate 2/Tag-align" )

			wait
		}

		if ( !no_xcor ) {
			// cross-corr. analysis
			subsampled_tag_xcor := subsample_tag( tag, parse_number( subsample_xcor ), aln_o_dir, group )
			wait

			// xcor
			string xcor_qc_, xcor_plot_
			( xcor_qc_, xcor_plot_ ) = xcor( subsampled_tag_xcor, qc_o_dir, group, nth_rep )

			xcor_qc{rep} = xcor_qc_
			xcor_plot{rep} = xcor_plot_

			add_file_to_report( final_tag_, "tag-align", group, "Alignment/$long/Tag-align" )
			add_file_to_table( xcor_plot_, "QC and logs/$long/Cross-corr. plot" )

			wait
			if ( pbc_qc_ && read_length_log ) \
				add_ENCODE_quality_metrics_to_summary_json( "complexity_xcorr_quality_metric", \
					"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", \
					[filt_bam_], [pbc_qc_, xcor_qc_, read_length_log], [ "false", xcor_plot_] )
		}
	}
}

void align_PE( int rep, int nth_rep ) {

	group 	:= get_group_name( rep )
	long 	:= get_long_group_name( rep )

	aln_o_dir := mkdir( "$out_dir/align/$group" ) // create align output directory
	qc_o_dir  := mkdir( "$out_dir/qc/$group" ) // create qc output dir.

	string bam_, align_log_, read_length_log, flagstat_qc_
	string[] fastqs_pair1, fastqs_pair2

	if ( is_input_fastq( rep ) ) {

		fastqs_pair1 = get_fastq( 0, rep, 1 )
		fastqs_pair2 = get_fastq( 0, rep, 2 )

		string[] trimmed_fastqs_pair1, trimmed_fastqs_pair2

		if ( fastqs_pair1.size() != fastqs_pair2.size() ) {
			error("Number of fastqs to be pooled for pair 1 and pair 2 do not match!\n")
		}
		for ( int i=0; i<fastqs_pair1.size(); i++) {
			id := i+1
			suffix := fastqs_pair1.size()==1 ? "" : ":$id"

			add_file_to_report( fastqs_pair1[i], "fastq 1$suffix", group, "Alignment/$long/Fastq 1$suffix" )
			add_file_to_report( fastqs_pair2[i], "fastq 2$suffix", group, "Alignment/$long/Fastq 2$suffix" )

			if ( trimmed_fastq ) {
				trimmed_fastqs_pair1.add( fastqs_pair1[i] )
				trimmed_fastqs_pair2.add( fastqs_pair2[i] )
			}
			else {
				string p1, p2
				if ( old_trimmer ) {
					( p1, p2 ) = trim_adapters_PE_old( fastqs_pair1[i], fastqs_pair2[i], \
									aln_o_dir, group, suffix )
				}
				else {
					adapters := get_adapters( rep )

					if ( adapters.size()==0 ) {
						string adapter_log1, adapter_log2, tid1, tid2						
						(adapter_log1, tid1) = detect_adapter( fastqs_pair1[i], qc_o_dir, group )
						(adapter_log2, tid2) = detect_adapter( fastqs_pair2[i], qc_o_dir, group )
						wait [tid1, tid2]

						adapter1 := parse_adapter_log( adapter_log1 )
						adapter2 := parse_adapter_log( adapter_log2 )

						print("\nDetected adapter for $group (PE) : $adapter1, $adapter2\n")
						adapters.add( adapter1 )
						adapters.add( adapter2 )
					}

					( p1, p2 ) = trim_adapters_PE( fastqs_pair1[i], fastqs_pair2[i], \
									adapters[0], adapters[1], aln_o_dir, group, suffix )
				}

				trimmed_fastqs_pair1.add( p1 )
				trimmed_fastqs_pair2.add( p2 )

				add_file_to_report( p1, "trimmed\\nfastq 1$suffix", group, "Alignment/$long/Trimmed fastq 1$suffix" )
				add_file_to_report( p2, "trimmed\\nfastq 2$suffix", group, "Alignment/$long/Trimmed fastq 2$suffix" )
			}
			if ( i==0 ) read_length_log = get_read_length_log( trimmed_fastqs_pair1[0], qc_o_dir, group )
		}
		wait

		string p1, p2
		if ( trimmed_fastqs_pair1.size() > 1 ) { // if multiple fastqs are given, pool trimmed fastqs
			p1 = pool_fastq( trimmed_fastqs_pair1, aln_o_dir, group )
			p2 = pool_fastq( trimmed_fastqs_pair2, aln_o_dir, group )
			add_file_to_report( p1, "pooled\\nfastq 1" , group, "Alignment/$long/Pooled fastq 1" )
			add_file_to_report( p2, "pooled\\nfastq 2" , group, "Alignment/$long/Pooled fastq 2" )
			wait
		}
		else {
			p1 = trimmed_fastqs_pair1[0]
			p2 = trimmed_fastqs_pair2[0]
		}

		fastq{rep+",1"} = p1
		fastq{rep+",2"} = p2

		( bam_, align_log_ ) = bowtie2_PE( p1, p2, aln_o_dir, qc_o_dir, group, nth_rep, !trimmed_fastq )
		wait

		flagstat_qc_ = samtools_flagstat_bam( bam_, qc_o_dir, group )

		bam{rep} = bam_
		align_log{rep} = align_log_
		flagstat_qc{rep} = flagstat_qc_

		add_file_to_report( bam_, "bam", group, "Alignment/$long/Bam" )		
		add_file_to_table( align_log_, "QC and logs/$long/Bowtie2 map. log")
		add_file_to_table( flagstat_qc_, "QC and logs/$long/Bowtie2 map. flagstat log")
	}

	string filt_bam_, dup_qc_, pbc_qc_

	if ( is_input_fastq( rep ) || is_input_bam( rep ) ) {

		if ( is_input_bam( rep ) ) {
			bam_ = get_bam( 0, rep )
			bam{rep} = bam_
		}

		if ( no_dup_removal ) {
			string tmp
			(filt_bam_, tmp ) \
				= dedup_bam_PE( bam_, aln_o_dir, qc_o_dir, group, nth_rep )
		}
		else {		
			(filt_bam_, dup_qc_, flagstat_nodup_qc{rep}, pbc_qc_ ) \
				= dedup_bam_PE( bam_, aln_o_dir, qc_o_dir, group, nth_rep )
			dup_qc{rep} = dup_qc_
			pbc_qc{rep} = pbc_qc_
			add_file_to_table( dup_qc_, "QC and logs/$long/Dedup. log")
		}

		filt_bam{rep} = filt_bam_
		add_file_to_report( filt_bam_, "filt. bam", group, "Alignment/$long/Filtered & deduped bam" )

		wait

		if ( fastqs_pair1.size() > 0 || fastqs_pair2.size() > 0 ) \
			add_ENCODE_metadata_to_summary_json( "bam", "", "alignments", \
				"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", \
				filt_bam_, fastqs_pair1+fastqs_pair2 )
		if ( flagstat_qc_) { 
			add_ENCODE_quality_metrics_to_summary_json( "samtools_flagstats_quality_metric", \
				"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", [filt_bam_], [flagstat_qc_] )
		}
	}

	string bedpe, subsampled_bedpe, tag

	if ( is_input_fastq( rep ) || is_input_bam( rep ) || is_input_filt_bam( rep ) ) {

		if ( is_input_filt_bam( rep ) ) {
			filt_bam_ = get_filt_bam( 0, rep )
			filt_bam{rep} = filt_bam_
		}

		bedpe = bam_to_bedpe( filt_bam_, aln_o_dir, group )
		wait

		if ( parse_number( subsample )!=0 ) {

			subsampled_bedpe = subsample_bedpe( bedpe, parse_number( subsample ), aln_o_dir, group )
		}
		else {
			subsampled_bedpe = bedpe
		}
		wait

		tag = bedpe_to_tag( subsampled_bedpe, aln_o_dir, group )
		wait
	}

	string final_tag_, final_tag_pr1_, final_tag_pr2_

	if ( is_input_fastq( rep ) || is_input_bam( rep ) || is_input_filt_bam( rep ) || is_input_tag( rep ) ) {

		if ( is_input_tag( rep ) ) tag = get_tag( 0, rep )

		string aln_pr1_o_dir, aln_pr2_o_dir
		string tag_pr1, tag_pr2

		if ( !true_rep ) {

			aln_pr1_o_dir = mkdir( "$out_dir/align/pseudo_reps/$group/pr1" )
			aln_pr2_o_dir = mkdir( "$out_dir/align/pseudo_reps/$group/pr2" )

			if ( is_input_tag( rep ) ) {
				( tag_pr1, tag_pr2 ) = spr_tag_PE( tag, aln_pr1_o_dir, aln_pr2_o_dir, group )
			}
			else {
				( tag_pr1, tag_pr2 ) = spr_PE( subsampled_bedpe, aln_pr1_o_dir, aln_pr2_o_dir, group )
			}
			wait
		}

		if ( is_dnase_seq() ) {
			final_tag_ = tag
		}
		else {
			final_tag_ = tn5_shift_tag( tag, aln_o_dir, group )
		}		
		final_tag{rep} = final_tag_

		add_file_to_report( final_tag_, "tag-align", group, "Alignment/$long/Tag-align" )

		if ( !true_rep ) {

			if ( is_dnase_seq() ) {
				final_tag_pr1_ = tag_pr1
				final_tag_pr2_ = tag_pr2
			}
			else {
				final_tag_pr1_ = tn5_shift_tag( tag_pr1, aln_pr1_o_dir, group )
				final_tag_pr2_ = tn5_shift_tag( tag_pr2, aln_pr2_o_dir, group )
			}
			final_tag_pr1{rep} = final_tag_pr1_
			final_tag_pr2{rep} = final_tag_pr2_

			add_file_to_report( final_tag_pr1_, "tag-align", "$group-pr1", \
				"Alignment/Pseudo-replicates/$long/Pseudo-replicate 1/Tag-align" )
			add_file_to_report( final_tag_pr2_, "tag-align", "$group-pr2", \
				"Alignment/Pseudo-replicates/$long/Pseudo-replicate 2/Tag-align" )			
		}
		wait

		# Ivar: Skip sub sample correlation analysis now
		if(false){
			string subsampled_tag_xcor

			if ( bedpe == "" ) {
				subsampled_tag_xcor = subsample_tag_PE_xcor( tag, parse_number( subsample_xcor ), aln_o_dir, group )
			}
			else {
				subsampled_tag_xcor = subsample_bedpe_to_tag_xcor( bedpe, parse_number( subsample_xcor ), aln_o_dir, group )
			}
			wait

<<<<<<< HEAD
=======
		if ( !no_xcor ) {
>>>>>>> 9ea6309fb5e4350bf6a34ff517ea7d50de5e9c88
			// cross-corr. analysis
			string xcor_qc_, xcor_plot_
			( xcor_qc_, xcor_plot_ ) = xcor( subsampled_tag_xcor, qc_o_dir, group, nth_rep ) 

			xcor_qc{rep} = xcor_qc_
			xcor_plot{rep} = xcor_plot_

			add_file_to_report( final_tag_, "tag-align", group, "Alignment/$long/Tag-align" )
			add_file_to_table( xcor_plot_, "QC and logs/$long/Cross-corr. plot" )
<<<<<<< HEAD
		}
		}
=======

			wait

			if ( pbc_qc_ && read_length_log ) \
				add_ENCODE_quality_metrics_to_summary_json( "complexity_xcorr_quality_metric", \
					"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1", \
					[filt_bam_], [pbc_qc_, xcor_qc_, read_length_log], [ "true", xcor_plot_] )			
		}
	}
>>>>>>> 9ea6309fb5e4350bf6a34ff517ea7d50de5e9c88
}

void read_input_peak() {

	if ( !is_input_peak() ) return // read peaks here

	for ( int rep=0; rep<=get_num_rep_peak(); rep++) { // rep==0 : pooled
		if ( get_num_rep_peak() == 1 && rep==0 ) continue // if only one replicate, skip reading pooled rep

		for (int pse=0; pse<=2; pse++) { // pse==0 : true rep
			if ( true_rep && pse > 0 ) continue			

			peak_ := get_peak(rep,pse)

			if ( rep == 0 ) {
				if ( pse == 0 )		peak_pooled 	= peak_
				else if ( pse == 1 )	peak_ppr1	= peak_
				else if ( pse == 2 )	peak_ppr2 	= peak_
			}
			else {
				if ( pse == 0 )		peak{rep} 	= peak_
				else if ( pse == 1 )	peak_pr1{rep}	= peak_
				else if ( pse == 2 )	peak_pr2{rep}	= peak_
			}
		}
	}
}

void call_peaks() { // for pooling two replicates and calling peaks on them

	if ( align ) return
	if ( is_input_peak() ) return

	// pool tag-aligns
	string[] tags, tags_pr1, tags_pr2

	for ( int rep=1; rep<=get_num_rep(); rep++ ) {

		tags.add( final_tag{rep} )

	 	if ( !true_rep ) {
			tags_pr1.add( final_tag_pr1{rep} )
			tags_pr2.add( final_tag_pr2{rep} )
		}
	}

	string final_tag_pooled, final_tag_ppr1, final_tag_ppr2
	
	if ( get_num_rep() > 1 ) {

	 	aln_pooled_o_dir := mkdir( "$out_dir/align/pooled_rep" )

		final_tag_pooled = pool_tag( tags, aln_pooled_o_dir, "pooled_rep" )

		add_file_to_report( final_tag_pooled, "tag-align", "pooled_rep", "Alignment/Pooled replicate/Tag-align" )

		if ( !true_rep ) {

			// Make shifted tags for pooled pseudo rep (ppr).
		 	aln_ppr1_o_dir   := mkdir( "$out_dir/align/pooled_pseudo_reps/ppr1" )
		 	aln_ppr2_o_dir   := mkdir( "$out_dir/align/pooled_pseudo_reps/ppr2" )

			final_tag_ppr1 = pool_tag( tags_pr1, aln_ppr1_o_dir, "ppr1" )
			final_tag_ppr2 = pool_tag( tags_pr2, aln_ppr2_o_dir, "ppr2" )

			add_file_to_report( final_tag_ppr1, "tag-align", "ppr1", "Alignment/Pooled pseudo-replicates/Pooled pseudo-replicate 1/Tag-align" )
			add_file_to_report( final_tag_ppr2, "tag-align", "ppr2", "Alignment/Pooled pseudo-replicates/Pooled pseudo-replicate 2/Tag-align" )			
		}

		wait
	}

	// call peaks for each replicate
	for ( int rep=1; rep<=get_num_rep(); rep++ ) {

		group 	:= get_group_name( rep )
		long 	:= get_long_group_name( rep )

		// call peaks
		peak_o_dir 	:= mkdir( "$out_dir/peak/macs2/$group")
		sig_o_dir 	:= mkdir( "$out_dir/signal/macs2/$group" )

		// macs2 pval thresh = 0.01, signal track generation = true
		( peak_001{rep}, gpeak_001{rep}, fc_bigwig_001{rep}, pval_bigwig_001{rep} ) \
				= macs2_atac( final_tag{rep}, "$smooth_win", 0.01, true, peak_o_dir, sig_o_dir, group )

		add_file_to_report( peak_001{rep}, "n. peak\\np-val<0.01", group, "Peaks/MACS2/$long/Narrow peak (p-val thresh=.01)" )
		add_file_to_report( gpeak_001{rep}, "g. peak\\np-val<0.01", group, "Peaks/MACS2/$long/Gapped peak (p-val thresh=.01)" )
		add_file_to_report( fc_bigwig_001{rep}, "signal fc", group, "Signal tracks/MACS2/$long/Fold enrichment" )
		add_file_to_report( pval_bigwig_001{rep}, "signal p-val", group, "Signal tracks/MACS2/$long/P-value" )

		// macs2 pval thresh = 0.1
		( peak{rep}, gpeak{rep} )  \
				= macs2_atac( final_tag{rep}, "$smooth_win", 0.1, false, peak_o_dir, sig_o_dir, group )

		add_file_to_report( peak{rep}, "n. peak", group, "Peaks/MACS2/$long/Narrow peak" )
		add_file_to_report( gpeak{rep}, "g. peak", group, "Peaks/MACS2/$long/Gapped peak" )

		if ( !true_rep ) {

			peak_pr1_o_dir 	:= mkdir( "$out_dir/peak/macs2/pseudo_reps/$group/pr1" )
			peak_pr2_o_dir 	:= mkdir( "$out_dir/peak/macs2/pseudo_reps/$group/pr2" )
			sig_pr1_o_dir 	:= mkdir( "$out_dir/signal/macs2/pseudo_reps/$group/pr1" )
			sig_pr2_o_dir 	:= mkdir( "$out_dir/signal/macs2/pseudo_reps/$group/pr2" )

			( peak_pr1{rep}, gpeak_pr1{rep} ) \
				= macs2_atac( final_tag_pr1{rep}, "$smooth_win", 0.1, false, peak_pr1_o_dir, sig_pr1_o_dir, "$group-pr1" )

			add_file_to_report( peak_pr1{rep}, "n. peak", "$group-pr1", "Peaks/MACS2/Pseudo-replicates/$long/Pseudo-replicate 1/Narrow peak" )
			add_file_to_report( gpeak_pr1{rep},"g. peak", "$group-pr1", "Peaks/MACS2/Pseudo-replicates/$long/Pseudo-replicate 1/Gapped peak" )

			( peak_pr2{rep}, gpeak_pr2{rep} ) \
				= macs2_atac( final_tag_pr2{rep}, "$smooth_win", 0.1, false, peak_pr2_o_dir, sig_pr2_o_dir, "$group-pr2" )

			add_file_to_report( peak_pr2{rep}, "n. peak", "$group-pr2", "Peaks/MACS2/Pseudo-replicates/$long/Pseudo-replicate 2/Narrow peak" )
			add_file_to_report( gpeak_pr2{rep},"g. peak", "$group-pr2", "Peaks/MACS2/Pseudo-replicates/$long/Pseudo-replicate 2/Gapped peak" )			
		}
	}

	// call peaks for pooled replicates
	if ( get_num_rep() > 1 ) {

		peak_o_dir 	:= mkdir( "$out_dir/peak/macs2")
		sig_o_dir 	:= mkdir( "$out_dir/signal/macs2")

		pooled_o_dir	:= mkdir( "$peak_o_dir/pooled_rep" )
		pooled_sig_o_dir:= mkdir( "$sig_o_dir/pooled_rep" )

		// macs2 on pooled reps with p-val threshold 0.01, signal tracks are generated
		( peak_pooled_001, gpeak_pooled_001, fc_bigwig_001{"pooled"}, pval_bigwig_001{"pooled"} ) \
			= macs2_atac( final_tag_pooled, "$smooth_win", 0.01, true, pooled_o_dir, pooled_sig_o_dir, "pooled_rep" )

		add_file_to_report( peak_pooled_001, "n. peak\\np-val<0.01", "pooled_rep", "Peaks/MACS2/Pooled replicate/Narrow peak (p-val thresh=.01)" )
		add_file_to_report( gpeak_pooled_001, "g. peak\\np-val<0.01", "pooled_rep", "Peaks/MACS2/Pooled replicate/Gapped peak (p-val thresh=.01)" )
		add_file_to_report( fc_bigwig_001{"pooled"}, "signal fc", "pooled_rep", "Signal tracks/MACS2/Pooled replicate/Fold enrichment" )
		add_file_to_report( pval_bigwig_001{"pooled"}, "signal p-val", "pooled_rep", "Signal tracks/MACS2/Pooled replicate/P-value" )

		// macs2 on pooled reps with p-val threshold 0.1
		( peak_pooled, gpeak_pooled ) \
			= macs2_atac( final_tag_pooled, "$smooth_win", 0.1, false, pooled_o_dir, pooled_sig_o_dir, "pooled_rep" )

		add_file_to_report( peak_pooled, "n. peak", "pooled_rep", "Peaks/MACS2/Pooled replicate/Narrow peak" )
		add_file_to_report( gpeak_pooled, "g. peak", "pooled_rep", "Peaks/MACS2/Pooled replicate/Gapped peak" )

		if ( !true_rep ) {

			ppr1_o_dir 	:= mkdir( "$peak_o_dir/pooled_pseudo_reps/ppr1" )
			ppr2_o_dir 	:= mkdir( "$peak_o_dir/pooled_pseudo_reps/ppr2" )
			ppr1_sig_o_dir 	:= mkdir( "$sig_o_dir/pooled_pseudo_reps/ppr1" )
			ppr2_sig_o_dir 	:= mkdir( "$sig_o_dir/pooled_pseudo_reps/ppr2" )

			// call peaks on ppr
			( peak_ppr1, gpeak_ppr1 ) = macs2_atac( final_tag_ppr1, "$smooth_win", 0.1, false, ppr1_o_dir, ppr1_sig_o_dir, "ppr1" )

			add_file_to_report( peak_ppr1, "n. peak", "ppr1", "Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 1/Narrow peak" )
			add_file_to_report( gpeak_ppr1, "g. peak", "ppr1","Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 1/Gapped peak" )

			( peak_ppr2, gpeak_ppr2 ) = macs2_atac( final_tag_ppr2, "$smooth_win", 0.1, false, ppr2_o_dir, ppr2_sig_o_dir, "ppr2" )

			add_file_to_report( peak_ppr2, "n. peak", "ppr2", "Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 2/Narrow peak" )
			add_file_to_report( gpeak_ppr2, "g. peak", "ppr2","Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 2/Gapped peak" )
		}
	}

	wait

	print( "\n== Done call_peaks()\n" )
}

void do_idr() {

	if ( align || no_idr ) return

	string{} top_peak, top_peak_pr1, top_peak_pr2
	string top_peak_pooled, top_peak_ppr1, top_peak_ppr2

	string{} filt_gpeak, filt_gpeak_pr1, filt_gpeak_pr2
	string filt_gpeak_pooled, filt_gpeak_ppr1, filt_gpeak_ppr2

	// take top $npeak_filt lines from narrowpeaks for idr
	for ( int rep=1; rep<=get_num_rep(); rep++ ) {

		top_peak{rep} 	= filt_top_peaks( "narrowPeak", peak{rep}, "", "rep$rep" )
		add_file_to_table( top_peak{rep}, "Peaks/MACS2/Replicate $rep/Filtered narrow peak" )

		if ( !is_input_peak() ) {
			filt_gpeak{rep} = filt_top_peaks( "gappedPeak", gpeak{rep}, "", "rep$rep" )
			add_file_to_table( filt_gpeak{rep},"Peaks/MACS2/Replicate $rep/Filtered gapped peak" )
		}

		if ( !true_rep ) {
			top_peak_pr1{rep}  = filt_top_peaks( "narrowPeak", peak_pr1{rep}, "", "rep$rep-pr1" )
			top_peak_pr2{rep}  = filt_top_peaks( "narrowPeak", peak_pr2{rep}, "", "rep$rep-pr2" )
			add_file_to_table( top_peak_pr1{rep}, \
				"Peaks/MACS2/Pseudo-replicates/Replicate $rep/Pseudo-replicate 1/Filtered narrow peak" )
			add_file_to_table( top_peak_pr2{rep}, \
				"Peaks/MACS2/Pseudo-replicates/Replicate $rep/Pseudo-replicate 2/Filtered narrow peak" )

			if ( !is_input_peak() ) {
				filt_gpeak_pr1{rep} = filt_top_peaks( "gappedPeak", gpeak_pr1{rep}, "", "rep$rep-pr1" )
				filt_gpeak_pr2{rep} = filt_top_peaks( "gappedPeak", gpeak_pr2{rep}, "", "rep$rep-pr2" )
				add_file_to_table( filt_gpeak_pr1{rep}, \
				"Peaks/MACS2/Pseudo-replicates/Replicate $rep/Pseudo-replicate 1/Filtered gapped peak" )
				add_file_to_table( filt_gpeak_pr2{rep}, \
				"Peaks/MACS2/Pseudo-replicates/Replicate $rep/Pseudo-replicate 2/Filtered gapped peak" )
			}
		}
	}

	if ( get_num_rep() > 1 ) {

		top_peak_pooled = filt_top_peaks( "narrowPeak", peak_pooled, "", "pooled_rep" )
		add_file_to_table( top_peak_pooled, "Peaks/MACS2/Pooled replicate/Filtered narrow peak" )

		if ( !is_input_peak() ) {
			filt_gpeak_pooled= filt_top_peaks( "gappedPeak", gpeak_pooled, "", "pooled_rep" )
			add_file_to_table( filt_gpeak_pooled, "Peaks/MACS2/Pooled replicate/Filtered gapped peak" )
		}

		if ( !true_rep ) {
			top_peak_ppr1 	= filt_top_peaks( "narrowPeak", peak_ppr1, "", "ppr1" )			
			top_peak_ppr2 	= filt_top_peaks( "narrowPeak", peak_ppr2, "", "ppr2" )
			add_file_to_table( top_peak_ppr1, \
				"Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 1/Filtered narrow peak" )
			add_file_to_table( top_peak_ppr2, \
				"Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 2/Filtered narrow peak" )

			if ( !is_input_peak() ) {
				filt_gpeak_ppr1 = filt_top_peaks( "gappedPeak", gpeak_ppr1, "", "ppr1" )
				filt_gpeak_ppr2 = filt_top_peaks( "gappedPeak", gpeak_ppr2, "", "ppr2" )
				add_file_to_table( filt_gpeak_ppr1, \
					"Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 1/Filtered gapped peak" )
				add_file_to_table( filt_gpeak_ppr2, \
					"Peaks/MACS2/Pooled pseudo-replicates/Pooled pseudo-replicate 2/Filtered gapped peak" )
			}
		}
	}

	wait

	// naive overlap peak

	overlap_o_dir := mkdir( "$out_dir/peak/macs2/overlap" )

	if ( get_num_rep() == 1 ) {

		if ( !true_rep ) {
			peak_overlap = naive_overlap_peak( "narrowPeak", \
						top_peak{1}, top_peak_pr1{1}, top_peak_pr2{1}, overlap_o_dir, "" )
			if ( !is_input_peak() ) \
				gpeak_overlap = naive_overlap_peak( "gappedPeak", \
						filt_gpeak{1}, filt_gpeak_pr1{1}, filt_gpeak_pr2{1}, overlap_o_dir, "" )
		}
	}
	else {
		peak_overlap = naive_overlap_peak( "narrowPeak", top_peak_pooled, map_to_array( top_peak ), \
								  top_peak_ppr1, top_peak_ppr2, overlap_o_dir, "" )

		if ( !is_input_peak() ) \
			gpeak_overlap = naive_overlap_peak( "gappedPeak", filt_gpeak_pooled, map_to_array( filt_gpeak ), \
								  filt_gpeak_ppr1, filt_gpeak_ppr2, overlap_o_dir, "" )
	}

	add_file_to_report( peak_overlap, "n. peak\\noverlap", "", "Peaks/MACS2/Naive overlap/Narrow peak" )
	if ( !is_input_peak() ) \
		add_file_to_report( gpeak_overlap, "g. peak\\noverlap", "", "Peaks/MACS2/Naive overlap/Gapped peak" )

	// do IDR

	idr_o_dir := mkdir( "$out_dir/peak/idr" )

	for ( int i=1; i<=get_num_rep(); i++ ) {

		for ( int j=i+1; j<=get_num_rep(); j++ ) {

			idr_true_o_dir 	:= mkdir( "$idr_o_dir/true_reps/rep$i-rep$j" )

			(idr_tr{"$i,$j"}, idr_tr_png{"$i,$j"}, idr_tr_log{"$i,$j"} ) \
				= idr2( top_peak{i}, top_peak{j}, top_peak_pooled, idr_thresh, "p.value", idr_true_o_dir, "rep$i-rep$j" )

			add_file_to_report( idr_tr{"$i,$j"}, "IDR peak", "rep$i-rep$j", "Peaks/IDR/True replicates/Rep. $i vs. Rep. $j/IDR peak" )
			add_file_to_table( idr_tr_png{"$i,$j"}, "QC and logs/IDR/True replicates/Rep. $i vs. Rep. $j/IDR plot" )
		}

		if ( !true_rep ) {

			idr_pr_o_dir := mkdir( "$idr_o_dir/pseudo_reps/rep$i" )

			(idr_pr{i}, idr_pr_png{i}, idr_pr_log{i}) \
				= idr2( top_peak_pr1{i}, top_peak_pr2{i}, top_peak{i}, idr_thresh, "p.value", idr_pr_o_dir, "rep$i-pr" )

			add_file_to_report( idr_pr{i}, "IDR peak", "rep$i-pr", "Peaks/IDR/Pseudo-replicates/Replicate $i/IDR peak" )
			add_file_to_table( idr_pr_png{i}, "QC and logs/IDR/Pseudo-replicates/Replicate $i/IDR plot" )
		}
	}

	if ( !true_rep && get_num_rep() > 1 ) {

		idr_ppr_o_dir := mkdir( "$idr_o_dir/pooled_pseudo_reps" )

		(idr_ppr, idr_ppr_png, idr_ppr_log) \
			= idr2( top_peak_ppr1, top_peak_ppr2, top_peak_pooled, idr_thresh, "p.value", idr_ppr_o_dir, "ppr" )

		add_file_to_report( idr_ppr, "IDR peak", "ppr", "Peaks/IDR/Pooled pseudo-replicates/IDR peak" )
		add_file_to_table( idr_ppr_png, "QC and logs/IDR/Pooled pseudo-replicates/IDR plot" )
	}

	wait

	qc_o_dir := mkdir( "$out_dir/qc" ) // create qc output dir.

	// get final idr qc score, use idr final idr narrow peak files from true, pseudo and pooled pseudo reps
	(idr_qc, idr_opt, idr_consv) = idr_final_qc( idr_tr, idr_pr, idr_ppr, idr_o_dir, qc_o_dir, "" )

	add_file_to_report( idr_qc, "IDR QC log", "", "QC and logs/IDR/IDR QC log" )
	add_file_to_report( idr_opt, "opt. IDR peak", "", "Peaks/IDR/Optimal set/IDR peak" )
	add_file_to_report( idr_consv, "consv. IDR peak", "", "Peaks/IDR/Conservative set/IDR peak" )

	wait

	print( "\n== Done do_idr()\n" )
}

// black list filter and then convert to bigbed (for true replicates only)
void filter_peak_and_convert_to_bigbed() { 
	if ( align ) return
	if ( !path_exists( blacklist ) ) return

	// peaks for true replicates
	if ( get_num_rep() > 1 ) {
		filt_peak_pooled_001 := \
			blacklist_filter_peak( "narrowPeak", peak_pooled_001, peak_pooled_001.dirName(), "peak_pooled" )
		filt_gpeak_pooled_001 := \
			blacklist_filter_peak( "gappedPeak", gpeak_pooled_001, gpeak_pooled_001.dirName(), "gpeak_pooled" )
		wait

		peak_to_bigbed( "narrowPeak", filt_peak_pooled_001, filt_peak_pooled_001.dirName(), "peak_pooled" )
		peak_to_bigbed( "gappedPeak", filt_gpeak_pooled_001, filt_gpeak_pooled_001.dirName(), "gpeak_pooled" )
	}

	string[] filt_peaks, filt_gpeaks
	for (int rep=1; rep<=get_num_rep(); rep++) {
		filt_peak_001 := \
			blacklist_filter_peak( "narrowPeak", peak_001{rep}, (peak_001{rep}).dirName(), "peak $rep" )
		filt_gpeak_001 := \
			blacklist_filter_peak( "gappedPeak", gpeak_001{rep}, (gpeak_001{rep}).dirName(), "gpeak $rep" )
		wait
		add_ENCODE_metadata_to_summary_json( "bed", "narrowPeak", "filtered peaks", \
			"anshul-kundaje:atac-seq-peaks-filter-step-run-v1", filt_peak_001, [filt_bam{rep}])
		add_ENCODE_metadata_to_summary_json( "bed", "gappedPeak", "filtered peaks", \
			"anshul-kundaje:atac-seq-peaks-filter-step-run-v1", filt_gpeak_001, [filt_bam{rep}])
		add_ENCODE_metadata_to_summary_json( "bigWig", "", "signal p-value", \
			"anshul-kundaje:atac-seq-signal-generation-step-run-v1", pval_bigwig_001{rep}, [filt_bam{rep}])
		add_ENCODE_metadata_to_summary_json( "bigWig", "", "fold change over control", \
			"anshul-kundaje:atac-seq-signal-generation-step-run-v1", fc_bigwig_001{rep}, [filt_bam{rep}])

		npeak_bb := peak_to_bigbed( "narrowPeak", filt_peak_001, filt_peak_001.dirName(), "peak $rep" )
		gpeak_bb := peak_to_bigbed( "gappedPeak", filt_gpeak_001, filt_gpeak_001.dirName(), "gpeak $rep" )

		wait
		add_ENCODE_metadata_to_summary_json( "bigBed", "narrowPeak", "filtered peaks", \
			"anshul-kundaje:atac-seq-peaks-to-bigbed-step-run-v1", npeak_bb, [filt_peak_001])
		add_ENCODE_metadata_to_summary_json( "bigBed", "gappedPeak", "filtered peaks", \
			"anshul-kundaje:atac-seq-peaks-to-bigbed-step-run-v1", gpeak_bb, [filt_gpeak_001])

		filt_peaks.add(filt_peak_001)
		filt_gpeaks.add(filt_gpeak_001)
	}

	wait

	if ( idr_qc && idr_opt && idr_consv ) {

		string[] idr_ENCODE 
		// IDR peaks
		if ( idr_pr.hasKey(1) && get_num_rep()==1 ) {
			idr_ENCODE = [idr_pr{1}]
			add_ENCODE_metadata_to_summary_json( "bed", "narrowPeak", "pseudoreplicated idr thresholded peaks", \
				"anshul-kundaje:atac-seq-idr-step-run-v1", idr_pr{1}, filt_peaks )
			idr_bb := peak_to_bigbed( "narrowPeak", idr_pr{1}, idr_pr{1}.dirName(), "idr peak pr" )
			wait
			add_ENCODE_metadata_to_summary_json( "bigBed", "narrowPeak", "pseudoreplicated idr thresholded peaks", \
				"anshul-kundaje:atac-seq-idr-peaks-conversion-step-run-v1", idr_bb, [idr_pr{1}] )
		}
		else {
			// find idr_opt and idr_consv		
			idr_ENCODE = [idr_opt] //, idr_consv]
			add_ENCODE_metadata_to_summary_json( "bed", "narrowPeak", "optimal idr thresholded peaks", \
				"anshul-kundaje:atac-seq-idr-step-run-v1", idr_opt, filt_peaks )
			idr_opt_bb := peak_to_bigbed( "narrowPeak", idr_opt, idr_opt.dirName(), "idr peak opt" )
			wait
			add_ENCODE_metadata_to_summary_json( "bigBed", "narrowPeak", "optimal idr thresholded peaks", \
				"anshul-kundaje:atac-seq-idr-peaks-conversion-step-run-v1", idr_opt_bb, [idr_opt])

			if ( idr_consv && get_basename( idr_opt )!=get_basename( idr_consv ) ) {
				add_ENCODE_metadata_to_summary_json( "bed", "narrowPeak", "conservative idr thresholded peaks", \
					"anshul-kundaje:atac-seq-idr-step-run-v1", idr_consv, filt_peaks )
				idr_consv_bb := peak_to_bigbed( "narrowPeak", idr_consv, idr_consv.dirName(), "idr peak consv" )
				wait
				add_ENCODE_metadata_to_summary_json( "bigBed", "narrowPeak", "conservative idr thresholded peaks", \
					"anshul-kundaje:atac-seq-idr-peaks-conversion-step-run-v1", idr_consv_bb, [idr_consv] )
			}
		}
		add_ENCODE_quality_metrics_to_summary_json( "idr_quality_metric", \
			"anshul-kundaje:atac-seq-idr-step-run-v1", \
			idr_ENCODE, [idr_qc], \
			[ idr_thresh, \
			idr_tr_png.hasKey("1,2") ? idr_tr_png{"1,2"} : "", idr_pr_png{1}, \
				idr_pr_png.hasKey(2) ? idr_pr_png{2} : "", idr_ppr_png, \
			idr_tr_log.hasKey("1,2") ? idr_tr_log{"1,2"} : "", idr_pr_log{1}, \
				idr_pr_log.hasKey(2) ? idr_pr_log{2} : "", idr_ppr_log] )
	}

	// naive overlap peaks
	if ( peak_overlap ) {
		add_ENCODE_metadata_to_summary_json( "bed", "narrowPeak", "replicated peaks", \
			"anshul-kundaje:atac-seq-overlap-step-run-v1", peak_overlap, filt_peaks )
		npeak_bb := peak_to_bigbed( "narrowPeak", peak_overlap, peak_overlap.dirName(), "peak overlap" )
		wait
		add_ENCODE_metadata_to_summary_json( "bigBed", "narrowPeak", "replicated peaks", \
			"anshul-kundaje:atac-seq-replicated-peaks-conversion-step-run-v1", npeak_bb, [peak_overlap] )
	}

	if ( gpeak_overlap ) {
		add_ENCODE_metadata_to_summary_json( "bed", "gappedPeak", "replicated peaks", \
			"anshul-kundaje:atac-seq-overlap-step-run-v1", gpeak_overlap, filt_gpeaks )
		gpeak_bb := peak_to_bigbed( "gappedPeak", gpeak_overlap, gpeak_overlap.dirName(), "gpeak overlap" )
		wait
		add_ENCODE_metadata_to_summary_json( "bigBed", "gappedPeak", "replicated peaks", \
			"anshul-kundaje:atac-seq-replicated-peaks-conversion-step-run-v1", gpeak_bb, [gpeak_overlap] )
	}

	wait

	print( "\n== Done filter_peak_and_convert_to_bigbed()\n" )	
}

void ataqc() {

	if ( no_ataqc || align ) return
	if ( is_input_peak() ) return

	for (int rep=1; rep<=get_num_rep(); rep++) {

		if ( no_par ) ataqc( rep )
		else 	  par ataqc( rep )
	}

	wait

	print( "\n== Done ataqc()\n" )
}

void ataqc( int rep ) {

	if ( true_rep || no_idr ) {
		print("Warning: ATAQC cannot run with the flag -true_rep or -no_idr\n");
		return
	}
	if ( no_dup_removal ) {
		print("Warning: ATAQC cannot run with the flag -no_dup_removal\n");
		return
	}

	group := get_group_name( rep )
	long  := get_long_group_name( rep )

	qc_o_dir 	:= mkdir( "$out_dir/qc/$group" )
	aln_o_dir 	:= mkdir( "$out_dir/align/$group" ) // create align output directory

	if ( bam.hasKey(rep) ) {

		string idr_ataqc, peak

		if ( no_idr ) 			{
			idr_ataqc = ""
		}
		else if ( get_num_rep() == 1 ) 	{
			idr_ataqc = idr_pr{1}
			peak = idr_pr{rep}
		}
		else {
			idr_ataqc = idr_opt
			peak = idr_pr{rep}
		}

		string ataqc_html

		if ( is_se( rep ) ) {

			( ataqc_html, ataqc_qc{rep} ) = ataqc( fastq{rep}, "", bam{rep}, align_log{rep}, pbc_qc{rep}, \
				dup_qc{rep}, filt_bam{rep}, final_tag{rep}, pval_bigwig_001{rep}, peak, \
				peak_overlap, idr_ataqc, qc_o_dir, group )
		}
		else {
			( ataqc_html, ataqc_qc{rep} ) = ataqc( fastq{rep+",1"}, fastq{rep+",2"}, bam{rep}, align_log{rep}, pbc_qc{rep}, \
				dup_qc{rep}, filt_bam{rep}, final_tag{rep}, pval_bigwig_001{rep}, peak, \
				peak_overlap, idr_ataqc, qc_o_dir, group )
		}

		add_file_to_report( ataqc_html, "ATAQC\\nreport", group, "QC and logs/ATAQC/$long/ATAQC HTML report" )
	}
}

<<<<<<< HEAD
string[] ataqc( string fastq1, string fastq2, string bam, string align_log, string pbc_log, \
		 string dup_log, string filt_bam, string bed, string bigwig, string peak, \
		 string peak_naive_overlap, string idr_peak, string o_dir, string group ) {

	prefix 		:= replace_dir( rm_ext( fastq1, ["fastq","fq"] ), o_dir ) + ( (fastq2!="") ? ".PE2SE" : "" )

	html 		:= "$prefix"+"_qc.html"
	txt 		:= "$prefix"+"_qc.txt"
	prefix_basename := get_basename( prefix )

	param_fastq 	:= (fastq2!="") ? "--fastq1 $fastq1 --fastq2 $fastq2" : "--fastq1 $fastq1"
	param_overlap 	:= (peak_naive_overlap!="") ? "--naive_overlap_peaks $peak_naive_overlap" : ""
	param_idr 	:= (idr_peak!="") ? "--idr_peaks $idr_peak" : ""
	param_use_sambamba	:=	(use_sambamba_markdup) ? "--use_sambamba_markdup" : ""

	in  	:= (fastq2!="") ? [ fastq1, fastq2, bam, align_log, pbc_log, dup_log, filt_bam, bed, bigwig, peak ] \
				: [ fastq1, bam, align_log, pbc_log, dup_log, filt_bam, bed, bigwig, peak ]
	out 	:= [ html, txt ] //, gc_plot, hist_graph, lg_vplot, vplot, signal ]

	taskName:= "ataqc "+group
	mem := get_res_mem(mem_ataqc,1)
	max_java_heap 	:= binary_prefix( (mem==-1) ? parse_mem( mem_ataqc ) : (mem*3)/4 )
	timeout := get_res_wt(wt_ataqc)

	wait_par( cpus )

	tid := task( out<-in ) {

		sys $shcmd_init

		// To prevent java heap space error (Exception in thread "main" java.lang.OutOfMemoryError: Java heap space)
		sys export _JAVA_OPTIONS="-Xms256M -Xmx$max_java_heap -XX:ParallelGCThreads=1"
		//sys export _JAVA_OPTIONS="-Xms256M -Xmx728M -XX:ParallelGCThreads=1"


		sys cd $o_dir

		// # if PICARDROOT is not defined, then look into ../shared/picard* (default picard dir. in bioconda)
		sys if [ -f "$(which picard)" ]; then export PICARDROOT="$(dirname $(which picard))/../share/picard"*; fi

		sys $script_dir/ataqc/run_ataqc.py \
		    --workdir $o_dir \
		    --outdir $o_dir \
		    --outprefix $prefix_basename \
		    --genome $species \
		    --ref $ref_fa \
		    --tss $tss_enrich \
		    --dnase $dnase \
		    --blacklist $blacklist \
		    --prom $prom \
		    --enh $enh \
		    --reg2map $reg2map \
		    --meta $roadmap_meta \
		    --pbc $pbc_log\
		    $param_fastq \
		    --alignedbam $bam \
		    --alignmentlog $align_log \
		    --coordsortbam $bam \
		    --duplog $dup_log \
		    --finalbam $filt_bam \
		    --finalbed $bed \
		    --bigwig $bigwig \
		    --peaks $peak \
		    $param_overlap \
		    $param_idr \
		    $param_use_sambamba

		sys $shcmd_finalize
	}

	register_par( tid, cpus )

	add_task_to_graph( in, out, group, "ATAQC", grp_color_ataqc )

	return out
}

=======
>>>>>>> 9ea6309fb5e4350bf6a34ff517ea7d50de5e9c88
void report() {

	wait

	html := html_pipeline_version( "https://github.com/kundajelab/atac_dnase_pipelines/commit" ) // pipeline version info
	html += html_filetable() 	// treeview for directory and file structure
	html += html_atac_tracks() 	// epigenome browser tracks
	html += html_graph()	// graphviz workflow diagram
	html += html_atac_QC()	// show QC tables and images

	report( html )
	write_summary_json()

	print( "\n== Done report()\n" )
}

string html_atac_QC() {

	string[] align_qcs, flagstat_qcs, dup_qcs, flagstat_nodup_qcs, pbc_qcs, xcor_qcs, xcor_plots, ataqc_qcs
	string[] groups

	for ( int rep=1; rep <= get_num_rep(); rep++) {

		group := "rep$rep"
		key := "$rep"
		groups.add( group )

		if ( xcor_qc.hasKey( key ) )	{
			xcor_qcs 		+= xcor_qc{key}
			xcor_plots 		+= xcor_plot{key}
		}
		if ( flagstat_qc.hasKey( key ) )	flagstat_qcs 		+= flagstat_qc{key}
		if ( dup_qc.hasKey( key ) ) 		dup_qcs 		+= dup_qc{key}
		if ( flagstat_nodup_qc.hasKey( key ) )	flagstat_nodup_qcs 	+= flagstat_nodup_qc{key}
		if ( pbc_qc.hasKey( key ) ) 		pbc_qcs			+= pbc_qc{key}
		if ( ataqc_qc.hasKey( key ) )		ataqc_qcs		+= ataqc_qc{key}
	}

	html := "<div id='atac_qc'>"
	html += html_table_multiple_logs( "Flagstat (raw) QC", true, "flagstat", groups, flagstat_qcs )
	html += html_table_multiple_logs( "Dup. QC", true, "dup", groups, dup_qcs )
	html += html_table_multiple_logs( "Flagstat (filtered) QC", true, "flagstat_filt", groups, flagstat_nodup_qcs )
	html += html_table_multiple_logs( "PBC QC", true, "pbc", groups, pbc_qcs )
	if ( pbc_qcs.size()>0 ) html += html_help_pbc()
	html += html_table_multiple_logs( "Cross-corr. QC", true, "xcor", groups, xcor_qcs )
	if ( xcor_qcs.size()>0 ) html += html_help_xcor()

	// xcor images
	for ( int i=0; i<xcor_plots.size(); i++ ) {
		png := pdf_to_png( xcor_plots[i] )
		html += html_img( png, 500, groups[i] ) + "&nbsp"
	}

	// if idr qc's exists, add them to html
	if ( idr_qc != "" ) html += html_table_multiple_logs( "IDR QC", true, "idr", ["rep1"], [idr_qc] )
	for ( int i=1; i<=get_num_rep(); i++ ) {
		for ( int j=i+1; j<=get_num_rep(); j++ ) {
			if ( idr_tr_png.hasKey("$i,$j") ) \
				html += html_img( idr_tr_png{"$i,$j"}, 800, "true reps (rep$i-rep$j)" ) + "&nbsp"
		}
		if ( !true_rep ) {
			if ( idr_pr_png.hasKey(i) ) \
				html += html_img( idr_pr_png{i}, 800, "rep$i pseudo-reps" ) + "&nbsp"
		}
	}
	if ( idr_ppr_png != "" ) html += html_img( idr_ppr_png, 800, "pooled pseudo-reps" ) + "&nbsp"

	html += html_table_multiple_logs( "ATAQC", false, "ataqc", groups, ataqc_qcs )

	html += "</div><br>"
	return html
}

string html_atac_tracks() {

	string[] track_files, track_types, track_names

	if ( pval_bigwig_001.hasKey( "pooled" ) ) { track_types += "bigwig"; track_names += "$title pval (pooled)"; track_files += pval_bigwig_001{"pooled"} }

	if ( peak_overlap != "" ) { track_types += "hammock"; track_names += "$title peak overlap"; track_files += peak_to_hammock( peak_overlap ) }
	if ( gpeak_overlap != "" ) { track_types += "hammock"; track_names += "$title gpeak overlap"; track_files += peak_to_hammock( gpeak_overlap ) }
	if ( idr_opt != "" ) {	track_types += "hammock"; track_names += "$title peak idr (opt. set)"; track_files += peak_to_hammock( _get_idr_peak_trk( idr_opt ) ) } // find IDR tracks

	for (int rep=1; rep<=get_num_rep(); rep++) {

		if ( pval_bigwig_001.hasKey( "$rep" ) ) { track_types += "bigwig"; track_names += "$title pval (rep$rep)"; track_files += pval_bigwig_001{rep} }
		if ( peak_001.hasKey( "$rep" ) ) { track_types += "hammock"; track_names += "$title peak (rep$rep)"; track_files += peak_to_hammock( peak_001{rep} ) }
		if ( idr_pr.hasKey(rep) ) {	track_types += "hammock"; track_names += "$title peak idr (rep$rep-pr)"; track_files += peak_to_hammock( _get_idr_peak_trk( idr_pr{rep} ) ) }
	}

	html := html_epg_browser_viz( track_files, track_types, track_names, species_browser )

	return html
}

void help() {

	if ( is_cmd_line_arg_empty() ) {

		printHelp()
		exit
	}
}

bool is_atac_seq() {

	return type.toLower().startsWith( "atac" )
}

bool is_dnase_seq() {

	return type.toLower().startsWith( "dnase" )
}

